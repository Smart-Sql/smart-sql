## 基于 hadoop 的大数据架构
现在大数据的架构一般采用 hadoop 作为数据源。用 hive、spark、flink 来操作数据。因此第一步就是要将数据导入到 hadoop 集群。通常使用 sqoop 来完成这不操作，但是不排除导入数据不完整或者是错误。
Hive/spark/flink 因为读取的是 hadoop 上的文件，所以数据没有像关系型数据库那样的索引。
这样有如下弊端：
1、对多表 join 执行很慢 （绝大多数情况下都无法满足业务的要求）。
2、对多表的 join\order by \group by 以及聚合参数，会造成大量的mapreduce。效率低，可用性差。
3、对于复杂过程的数据抽取，通用的解决方案就是形成一张宽表，然而因为实际业务的特点，这样的宽表通常都有几百列甚至几千列。这样给运行和运维这样的宽表带来风险和挑战。
例如：一条 sql 语句就可以 outofmemory 造成整个系统不可以用。
4、形成宽表的过程，可能非常复杂，而增加相应的开发量和资源消耗。